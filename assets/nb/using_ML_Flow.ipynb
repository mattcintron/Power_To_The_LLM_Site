{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dHCornJDH6jK"
   },
   "source": [
    "\n",
    "## A Basic Overview of Using ML Flow \n",
    "\n",
    "ML flow is a tool for montoring and taracking ml runs with a full server UI here we go over some exaples of use and how it can be incorperted into a google colab.\n",
    "\n",
    "* orginal code refernce -\n",
    "https://stackoverflow.com/questions/61615818/setting-up-mlflow-on-google-colab \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iNUEtzYnG9Z0",
    "outputId": "2af3aecb-6fa7-43ea-8c5c-ddc65fcaa584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mlflow\n",
      "  Downloading mlflow-1.22.0-py3-none-any.whl (15.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 15.5 MB 12.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docker>=4.0.0\n",
      "  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n",
      "\u001b[K     |████████████████████████████████| 146 kB 13.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (5.3)\n",
      "Collecting databricks-cli>=0.8.7\n",
      "  Downloading databricks-cli-0.16.2.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 11.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: gitpython>=2.1.0 in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (3.1.14)\n",
      "Requirement already satisfied: click>=7.0 in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (7.0)\n",
      "Requirement already satisfied: requests>=2.17.3 in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (2.24.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.19.5)\n",
      "Collecting alembic<=1.4.1\n",
      "  Using cached alembic-1.4.1.tar.gz (1.1 MB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (20.1)\n",
      "Collecting querystring-parser\n",
      "  Using cached querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting prometheus-flask-exporter\n",
      "  Downloading prometheus_flask_exporter-0.18.6-py3-none-any.whl (17 kB)\n",
      "Collecting gunicorn; platform_system != \"Windows\"\n",
      "  Using cached gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.0.5)\n",
      "Requirement already satisfied: protobuf>=3.7.0 in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (3.13.0)\n",
      "Requirement already satisfied: pytz in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (2019.3)\n",
      "Requirement already satisfied: Flask in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.1.1)\n",
      "Requirement already satisfied: entrypoints in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (0.3)\n",
      "Requirement already satisfied: sqlalchemy in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.3.13)\n",
      "Collecting importlib-metadata!=4.7.0,>=3.7.0\n",
      "  Downloading importlib_metadata-4.8.2-py3-none-any.whl (17 kB)\n",
      "Collecting sqlparse>=0.3.1\n",
      "  Downloading sqlparse-0.4.2-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 3.2 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cloudpickle in /opt/anaconda3/lib/python3.7/site-packages (from mlflow) (1.3.0)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.2.3-py3-none-any.whl (53 kB)\n",
      "\u001b[K     |████████████████████████████████| 53 kB 4.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.7.7 in /opt/anaconda3/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (0.8.9)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/anaconda3/lib/python3.7/site-packages (from databricks-cli>=0.8.7->mlflow) (1.15.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from gitpython>=2.1.0->mlflow) (4.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2019.11.28)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (2.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.7/site-packages (from requests>=2.17.3->mlflow) (1.25.8)\n",
      "Collecting Mako\n",
      "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
      "\u001b[K     |████████████████████████████████| 75 kB 8.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting python-editor>=0.3\n",
      "  Using cached python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/lib/python3.7/site-packages (from alembic<=1.4.1->mlflow) (2.8.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/anaconda3/lib/python3.7/site-packages (from packaging->mlflow) (3.0.6)\n",
      "Requirement already satisfied: prometheus-client in /opt/anaconda3/lib/python3.7/site-packages (from prometheus-flask-exporter->mlflow) (0.7.1)\n",
      "Requirement already satisfied: setuptools>=3.0 in /opt/anaconda3/lib/python3.7/site-packages (from gunicorn; platform_system != \"Windows\"->mlflow) (46.0.0.post20200309)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/anaconda3/lib/python3.7/site-packages (from Flask->mlflow) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/anaconda3/lib/python3.7/site-packages (from Flask->mlflow) (1.0.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/anaconda3/lib/python3.7/site-packages (from Flask->mlflow) (2.11.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata!=4.7.0,>=3.7.0->mlflow) (3.7.4.3)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /opt/anaconda3/lib/python3.7/site-packages (from gitdb<5,>=4.0.1->gitpython>=2.1.0->mlflow) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /opt/anaconda3/lib/python3.7/site-packages (from Mako->alembic<=1.4.1->mlflow) (1.1.1)\n",
      "Building wheels for collected packages: databricks-cli, alembic\n",
      "  Building wheel for databricks-cli (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for databricks-cli: filename=databricks_cli-0.16.2-py3-none-any.whl size=106811 sha256=522ac4fa42a3bfc4d517b851819b157196c160c8ed5392ad4c9867094fdd633d\n",
      "  Stored in directory: /Users/micintro/Library/Caches/pip/wheels/f4/5c/ed/e1ce20a53095f63b27b4964abbad03e59cf3472822addf7d29\n",
      "  Building wheel for alembic (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158155 sha256=30fbb68afe86fcf4834728357003adb823f7c8c9ffac7fce942d901fea7f48a6\n",
      "  Stored in directory: /Users/micintro/Library/Caches/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
      "Successfully built databricks-cli alembic\n",
      "\u001b[31mERROR: pytest-astropy 0.8.0 requires pytest-cov>=2.0, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: pytest-astropy 0.8.0 requires pytest-filter-subpackage>=0.1, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: virtualenv 20.0.21 has requirement importlib-metadata<2,>=0.12; python_version < \"3.8\", but you'll have importlib-metadata 4.8.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: huggingface-hub 0.0.12 has requirement packaging>=20.9, but you'll have packaging 20.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: dvc 2.8.3 has requirement ruamel.yaml>=0.17.11, but you'll have ruamel-yaml 0.15.87 which is incompatible.\u001b[0m\n",
      "Installing collected packages: websocket-client, docker, databricks-cli, Mako, python-editor, alembic, querystring-parser, prometheus-flask-exporter, gunicorn, importlib-metadata, sqlparse, mlflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 1.5.0\n",
      "    Uninstalling importlib-metadata-1.5.0:\n",
      "      Successfully uninstalled importlib-metadata-1.5.0\n",
      "Successfully installed Mako-1.1.6 alembic-1.4.1 databricks-cli-0.16.2 docker-5.0.3 gunicorn-20.1.0 importlib-metadata-4.8.2 mlflow-1.22.0 prometheus-flask-exporter-0.18.6 python-editor-1.0.4 querystring-parser-1.2.4 sqlparse-0.4.2 websocket-client-1.2.3\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-5.1.0.tar.gz (745 kB)\n",
      "\u001b[K     |████████████████████████████████| 745 kB 469 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /opt/anaconda3/lib/python3.7/site-packages (from pyngrok) (5.3)\n",
      "Building wheels for collected packages: pyngrok\n",
      "  Building wheel for pyngrok (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyngrok: filename=pyngrok-5.1.0-py3-none-any.whl size=18990 sha256=4887e57eb940cba1d262d7df6ed8add385c9cb559432b4b90cf6a991f4cf583b\n",
      "  Stored in directory: /Users/micintro/Library/Caches/pip/wheels/bf/e6/af/ccf6598ecefecd44104069371795cb9b3afbcd16987f6ccfb3\n",
      "Successfully built pyngrok\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-5.1.0\n"
     ]
    }
   ],
   "source": [
    "#Here is the code (meant to be run on a Colab notebook)\n",
    "\n",
    "!pip install mlflow \n",
    "!pip install pyngrok "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iZlpRRAQJ4gU"
   },
   "outputs": [],
   "source": [
    "# first import the ML flow lib\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "q7tOKj7_KIAy"
   },
   "outputs": [],
   "source": [
    "# start ml flow and set starting run params\n",
    "with mlflow.start_run(run_name=\"MLflow on Colab\"):\n",
    "  mlflow.log_metric(\"m1\", 2.0)\n",
    "  mlflow.log_param(\"p1\", \"mlflow-colab\")\n",
    "\n",
    "# run tracking UI in the background\n",
    "get_ipython().system_raw(\"mlflow ui --port 5000 &\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e2UIciLPKtyy"
   },
   "source": [
    "### create remote tunnel using ngrok.com to allow local port access\n",
    "borrowed from \n",
    "<br><br>\n",
    "\n",
    "https://colab.research.google.com/github/alfozan/MLflow-GBRT-demo/blob/master/MLflow-GBRT-demo.ipynb#scrollTo=4h3bKHMYUIG6\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "U-SbqXcKKXmN"
   },
   "outputs": [],
   "source": [
    "#import pyngrok\n",
    "\n",
    "from pyngrok import ngrok\n",
    "\n",
    "# Terminate open tunnels if exist\n",
    "ngrok.kill()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XGt6z5jLGwR"
   },
   "source": [
    "### Setting the authtoken (optional)\n",
    "### Get your authtoken from \n",
    "https://dashboard.ngrok.com/auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQWLBpOKLBq4",
    "outputId": "f9124288-7dc9-4f31-afca-2afd34f28170"
   },
   "outputs": [],
   "source": [
    "NGROK_AUTH_TOKEN = \"1xiKn1eTJOmwpwdB4DtuzRRMXZf_6KBaaCrekZX8Vn7HQjQRP\"\n",
    "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K-qk5SplLUvT",
    "outputId": "98efb66a-8ba7-4bcb-874a-a1fc12f2fcc7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking UI: https://77cc-64-121-43-37.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
    "#if you are on the VPN you will have to disconect to use ngrok\n",
    "#also comment out any proxys in your bash\n",
    "\n",
    "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
    "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ZexaRtaD6YbL"
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"MLflow in Notebook\"):\n",
    "  mlflow.log_metric(\"m1\", 2.0)\n",
    "  mlflow.log_param(\"p1\", \"mlflow-colab\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RPhkXe0MLdiZ"
   },
   "source": [
    "# final summary \n",
    "The output of this notebook will be a pyngrok-generated URL like:\n",
    "\n",
    "MLflow Tracking UI: https://0a23d7a7d0c4.ngrok.io\n",
    "clicking on which will lead to an MLfLow GUI screen.\n",
    "\n",
    "(Slight modification of the original code thanks to pyngrok creator, Alex Laird)\n",
    "\n",
    "Tested with MLflow versions 1.10.0 and 1.11.0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pwqK_XQzNT9W"
   },
   "source": [
    "next try setting up some ml to track with ngrok tutorials \n",
    "https://dashboard.ngrok.com/get-started/tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "njDkFJxq7iOC"
   },
   "source": [
    "## Full SK learn ML Flow Tuorial -\n",
    "\n",
    "https://www.mlflow.org/docs/latest/tutorials-and-examples/tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aH7Xgc3-_whw"
   },
   "source": [
    "# Tutorial\n",
    "This tutorial showcases how you can use MLflow end-to-end to:\n",
    "\n",
    "Train a linear regression model\n",
    "\n",
    "Package the code that trains the model in a reusable and reproducible model format\n",
    "\n",
    "Deploy the model into a simple HTTP server that will enable you to score predictions\n",
    "\n",
    "This tutorial uses a dataset to predict the quality of wine based on quantitative features like the wine’s “fixed acidity”, “pH”, “residual sugar”, and so on. The dataset is from UCI’s machine learning repository. 1\n",
    "\n",
    "##Table of Contents\n",
    "\n",
    "What You’ll Need\n",
    "\n",
    "Training the Model\n",
    "\n",
    "Comparing the Models\n",
    "\n",
    "Packaging Training Code in a Conda Environment\n",
    "\n",
    "Specifying pip requirements using pip_requirements and extra_pip_requirements\n",
    "\n",
    "Serving the Model\n",
    "\n",
    "More Resources\n",
    "\n",
    "## What You’ll Need\n",
    "To run this tutorial, you’ll need to:\n",
    "\n",
    "PythonR\n",
    "Install MLflow and scikit-learn. There are two options for installing these dependencies:\n",
    "\n",
    "Install MLflow with extra dependencies, including scikit-learn (via pip install mlflow[extras])\n",
    "\n",
    "Install MLflow (via pip install mlflow) and install scikit-learn separately (via pip install scikit-learn)\n",
    "\n",
    "Install conda\n",
    "\n",
    "Clone (download) the MLflow repository via git clone https://github.com/mlflow/mlflow\n",
    "\n",
    "cd into the examples directory within your clone of MLflow - we’ll use this working directory for running the tutorial. We avoid running directly from our clone of MLflow as doing so would cause the tutorial to use MLflow from source, rather than your PyPI installation of MLflow.\n",
    "\n",
    "## Training the Model\n",
    "First, train a linear regression model that takes two hyperparameters: alpha and l1_ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oV1evS1nKnc4"
   },
   "outputs": [],
   "source": [
    "# The data set used in this example is from http://archive.ics.uci.edu/ml/datasets/Wine+Quality\n",
    "# P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
    "# Modeling wine preferences by data mining from physicochemical properties. In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QrlCc9QRAHae"
   },
   "outputs": [],
   "source": [
    "def eval_metrics(actual, pred):\n",
    "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    r2 = r2_score(actual, pred)\n",
    "    return rmse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O8ljxHC2BMC1"
   },
   "outputs": [],
   "source": [
    "def Build_ML_Flow():\n",
    "  warnings.filterwarnings(\"ignore\")\n",
    "  np.random.seed(40)\n",
    "\n",
    "  # Read the wine-quality csv file from the URL\n",
    "  csv_url = (\n",
    "      \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    "  )\n",
    "  try:\n",
    "      data = pd.read_csv(csv_url, sep=\";\")\n",
    "  except Exception as e:\n",
    "      logger.exception(\n",
    "          \"Unable to download training & test CSV, check your internet connection. Error: %s\", e\n",
    "      )\n",
    "\n",
    "\n",
    "\n",
    "  # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "  train, test = train_test_split(data)\n",
    "\n",
    "  # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "  train_x = train.drop([\"quality\"], axis=1)\n",
    "  test_x = test.drop([\"quality\"], axis=1)\n",
    "  train_y = train[[\"quality\"]]\n",
    "  test_y = test[[\"quality\"]]\n",
    "\n",
    "  try:\n",
    "    alpha = float(sys.argv[1]) if len(sys.argv) > 1 else 0.5\n",
    "  except:\n",
    "    alpha =0.5\n",
    "  try:\n",
    "    l1_ratio = float(sys.argv[2]) if len(sys.argv) > 2 else 0.5\n",
    "  except:\n",
    "    l1_ratio =0.5\n",
    "\n",
    "\n",
    "\n",
    "  #run ml flow\n",
    "  with mlflow.start_run():\n",
    "        lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "        lr.fit(train_x, train_y)\n",
    "\n",
    "        predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        print(\"  RMSE: %s\" % rmse)\n",
    "        print(\"  MAE: %s\" % mae)\n",
    "        print(\"  R2: %s\" % r2)\n",
    "\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l2MgEKwaAiQP",
    "outputId": "cd59168b-ee34-49ce-d53b-09d1fb8ead72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticnet model (alpha=0.500000, l1_ratio=0.500000):\n",
      "  RMSE: 0.7931640229276851\n",
      "  MAE: 0.6271946374319586\n",
      "  R2: 0.10862644997792614\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  Build_ML_Flow()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vKbCvpxVetZZ"
   },
   "source": [
    "# Show the example\n",
    "This example uses the familiar pandas, numpy, and sklearn APIs to create a simple machine learning model. The MLflow tracking APIs log information about each training run, like the hyperparameters alpha and l1_ratio, used to train the model and metrics, like the root mean square error, used to evaluate the model. The example also serializes the model in a format that MLflow knows how to deploy.\n",
    "\n",
    "You can run the example with default hyperparameters as follows:\n",
    "\n",
    "### Make sure the current working directory is 'examples'\n",
    "python sklearn_elasticnet_wine/train.py\n",
    "Try out some other values for alpha and l1_ratio by passing them as arguments to train.py:\n",
    "\n",
    "### Make sure the current working directory is 'examples'\n",
    "python sklearn_elasticnet_wine/train.py <alpha> <l1_ratio>\n",
    "Each time you run the example, MLflow logs information about your experiment runs in the directory mlruns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CQza7O-Ye8eC"
   },
   "source": [
    "## Comparing the Models\n",
    "Next, use the MLflow UI to compare the models that you have produced. In the same current working directory as the one that contains the mlruns run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E-_a4hQaAo2n",
    "outputId": "6d1cc0c0-da0b-4f6c-8480-b47c133939f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking UI: https://fea4-34-86-181-2.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
    "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
    "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFLb-OiS7d2d"
   },
   "source": [
    "#Train And Trak Keras Model with MLflow\n",
    "Trains and evaluate a simple MLP on the Reuters newswire topic classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "psqR6PpJCHDy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import reuters\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e55wvov8Ljy",
    "outputId": "96640f33-a036-4b77-f48d-edf114c6cdab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
      "2113536/2110848 [==============================] - 0s 0us/step\n",
      "2121728/2110848 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/mlflow/utils/autologging_utils/__init__.py:411: FutureWarning: Autologging support for keras >= 2.6.0 has been deprecated and will be removed in a future MLflow release. Use `mlflow.tensorflow.autolog()` instead.\n",
      "  return _autolog(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982 train sequences\n",
      "2246 test sequences\n"
     ]
    }
   ],
   "source": [
    "# The following import and function call are the only additions to code required\n",
    "# to automatically log metrics and parameters to MLflow.\n",
    "import mlflow.keras\n",
    "\n",
    "mlflow.keras.autolog()\n",
    "\n",
    "max_words = 1000\n",
    "batch_size = 32\n",
    "epochs = 5\n",
    "\n",
    "print(\"Loading data...\")\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=max_words, test_split=0.2)\n",
    "\n",
    "print(len(x_train), \"train sequences\")\n",
    "print(len(x_test), \"test sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dmm2gQ_f8Y6G",
    "outputId": "f376313e-1f7e-4e80-9613-1a1053412eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 classes\n",
      "Vectorizing sequence data...\n",
      "x_train shape: (8982, 1000)\n",
      "x_test shape: (2246, 1000)\n",
      "Convert class vector to binary class matrix (for use with categorical_crossentropy)\n",
      "y_train shape: (8982, 46)\n",
      "y_test shape: (2246, 46)\n"
     ]
    }
   ],
   "source": [
    "num_classes = np.max(y_train) + 1\n",
    "print(num_classes, \"classes\")\n",
    "\n",
    "print(\"Vectorizing sequence data...\")\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "x_train = tokenizer.sequences_to_matrix(x_train, mode=\"binary\")\n",
    "x_test = tokenizer.sequences_to_matrix(x_test, mode=\"binary\")\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"x_test shape:\", x_test.shape)\n",
    "\n",
    "print(\"Convert class vector to binary class matrix \" \"(for use with categorical_crossentropy)\")\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoYjD7DJ8obB",
    "outputId": "885d4f39-f8de-4eb1-8f48-15ea8eed6f56"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021/10/01 03:44:29 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '2b9415bf8613431ebeaadfb46622ca74', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current keras workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "253/253 [==============================] - 3s 7ms/step - loss: 1.4020 - accuracy: 0.6876 - val_loss: 1.0655 - val_accuracy: 0.7686\n",
      "Epoch 2/5\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.7792 - accuracy: 0.8157 - val_loss: 0.9578 - val_accuracy: 0.7864\n",
      "Epoch 3/5\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.5348 - accuracy: 0.8732 - val_loss: 0.8490 - val_accuracy: 0.8042\n",
      "Epoch 4/5\n",
      "253/253 [==============================] - 2s 6ms/step - loss: 0.4100 - accuracy: 0.8992 - val_loss: 0.8787 - val_accuracy: 0.8120\n",
      "Epoch 5/5\n",
      "253/253 [==============================] - 2s 7ms/step - loss: 0.3272 - accuracy: 0.9185 - val_loss: 0.9153 - val_accuracy: 0.8042\n",
      "INFO:tensorflow:Assets written to: /tmp/tmpdhfamig2/model/data/model/assets\n",
      "71/71 [==============================] - 0s 3ms/step - loss: 0.8927 - accuracy: 0.7876\n",
      "Test score: 0.8927369713783264\n",
      "Test accuracy: 0.7876224517822266\n"
     ]
    }
   ],
   "source": [
    "print(\"Building model...\")\n",
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(max_words,)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(\n",
    "    x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.1\n",
    ")\n",
    "score = model.evaluate(x_test, y_test, batch_size=batch_size, verbose=1)\n",
    "print(\"Test score:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aB3Grvyu9P47"
   },
   "source": [
    "## Review what you tracked in ml flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_N7c3j69BTP",
    "outputId": "9cc94748-dda4-4e7c-a9c0-7d79410d5f78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking UI: https://af10-35-221-157-132.ngrok.io\n"
     ]
    }
   ],
   "source": [
    "# Open an HTTPs tunnel on port 5000 for http://localhost:5000\n",
    "ngrok_tunnel = ngrok.connect(addr=\"5000\", proto=\"http\", bind_tls=True)\n",
    "print(\"MLflow Tracking UI:\", ngrok_tunnel.public_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLhkeh2G-iZB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "using ML Flow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
