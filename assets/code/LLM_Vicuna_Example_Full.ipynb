{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Vicuna\n",
        "### Introduction : Vicuna\n",
        "Team of researchers from UC Berkeley, CMU, Stanford, and UC San Diego developed this model. It was fine tuned on LLaMA using chat dataset extracted from ShareGPT website. The researchers claimed the model scored more than 90% quality of OpenAI ChatGPT-4. It's worth noting that its performance is almost equal to Bard. They used the training program of Alpaca and improved further on two aspects - multi-round conversations and long sequences."
      ],
      "metadata": {
        "id": "DtTQuyV6CLuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code breakdown locaked here - https://colab.research.google.com/drive/1jXBItb619tV4YknmRqzHMBJzAl_A9EbZ?usp=sharing"
      ],
      "metadata": {
        "id": "rOvlrdEtCo6x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Text Generation WebUI Vicuna"
      ],
      "metadata": {
        "id": "xA38dhigCwBD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/oobabooga/text-generation-webui\n",
        "%cd text-generation-webui\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "6f1QkvUrkI7F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4-bit Mode Support Setup"
      ],
      "metadata": {
        "id": "Ot1M2JsYjz4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir /content/text-generation-webui/repositories/\n",
        "%cd /content/text-generation-webui/repositories/\n",
        "!git clone https://github.com/oobabooga/GPTQ-for-LLaMa.git -b cuda\n",
        "%cd GPTQ-for-LLaMa\n",
        "!pip install ninja\n",
        "!pip install -r requirements.txt\n",
        "!python setup_cuda.py install"
      ],
      "metadata": {
        "id": "tsNqlAOMj1Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Model\n",
        "\n",
        "For **gpt4-x-alpaca-13b**\n",
        "\n",
        "*   anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g\n",
        "*   https://huggingface.co/anon8231489123/gpt4-x-alpaca-13b-native-4bit-128g/resolve/main/gpt-x-alpaca-13b-native-4bit-128g-cuda.pt\n",
        "\n",
        "For **vicuna-13b**\n",
        "\n",
        "*   anon8231489123/vicuna-13b-GPTQ-4bit-128g\n",
        "*   https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g/resolve/main/vicuna-13b-4bit-128g.safetensors\n"
      ],
      "metadata": {
        "id": "UZZsptE6hQEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/text-generation-webui/\n",
        "!python download-model.py --text-only anon8231489123/vicuna-13b-GPTQ-4bit-128g\n",
        "!wget https://huggingface.co/anon8231489123/vicuna-13b-GPTQ-4bit-128g/resolve/main/vicuna-13b-4bit-128g.safetensors\n"
      ],
      "metadata": {
        "id": "uxR3IwsFKosI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Move .pt or .safetensors file to /models/...**"
      ],
      "metadata": {
        "id": "2MVQqykpf14m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/text-generation-webui/vicuna-13b-4bit-128g.safetensors /content/text-generation-webui/models/anon8231489123_vicuna-13b-GPTQ-4bit-128g/anon8231489123_vicuna-13b-4bit-128g.safetensors"
      ],
      "metadata": {
        "id": "4cWhB7fOfPZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Application"
      ],
      "metadata": {
        "id": "2DxYjSoyh73Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To fix this error - AttributeError: module 'PIL.Image' has no attribute 'Resampling'\n",
        "# Restart runtime after this\n",
        "!pip install --ignore-installed Pillow==9.3.0"
      ],
      "metadata": {
        "id": "jAFpPc_uM1Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/text-generation-webui/\n",
        "!python server.py --share --model anon8231489123_vicuna-13b-GPTQ-4bit-128g --model_type llama --chat --wbits 4 --groupsize 128"
      ],
      "metadata": {
        "id": "meBEdsO1KpjJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}